import cv2
import torch
import numpy as np
import pyttsx3  # Text-to-Speech
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
import threading
import queue
from collections import Counter

class EyeOfOden:
    def __init__(self):
        # Load AI Vision Model
        self.model = YOLO("yolov8x.pt")  # YOLOv8-X for extreme accuracy
        self.tracker = DeepSort(max_age=30)  # Advanced Object Tracker

        # Camera Initialization
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            raise Exception("Failed to open webcam")

        # Text-to-Speech Engine with Threading
        self.speech_queue = queue.Queue()
        self.tts = pyttsx3.init()
        self.tts.setProperty("rate", 150)  # Adjust speaking speed
        self.speech_thread = threading.Thread(target=self._speech_loop, daemon=True)
        self.speech_thread.start()

        # Class Labels (COCO dataset subset)
        self.class_labels = {0: "person", 1: "bicycle", 2: "car", 3: "motorcycle", 56: "chair", 58: "bench"}
        
        # Action Mapping
        self.action_map = {
            "person": {"moving": "walking", "stationary": "standing"},
            "car": {"moving": "driving", "stationary": "parked"},
            "bicycle": {"moving": "riding", "stationary": "stopped"},
            "motorcycle": {"moving": "riding", "stationary": "stopped"}
        }

        # Tracking State
        self.frame_counter = 0
        self.previous_track_ids = set()
        self.last_spoken = {}  # Avoid repetitive announcements

    def _speech_loop(self):
        """Run TTS in a separate thread to prevent blocking."""
        while True:
            message = self.speech_queue.get()
            if message is None:
                break
            self.tts.say(message)
            self.tts.runAndWait()
            self.speech_queue.task_done()

    def speak(self, message):
        """Add message to speech queue."""
        # Avoid repeating messages too quickly
        if message not in self.last_spoken or self.last_spoken[message] > 30:  # ~1 second at 30 fps
            self.speech_queue.put(message)
            self.last_spoken[message] = 0
        # Increment counters for all spoken messages
        for key in list(self.last_spoken.keys()):
            self.last_spoken[key] += 1
            if self.last_spoken[key] > 60:  # Clear old entries
                del self.last_spoken[key]

    def get_location(self, box, frame_width):
        """Determine object location in frame (left, center, right)."""
        x_center = (box[0] + box[2]) / 2
        if x_center < frame_width / 3:
            return "left"
        elif x_center < 2 * frame_width / 3:
            return "center"
        else:
            return "right"

    def get_distance(self, box, frame_height):
        """Estimate distance based on bounding box height."""
        height = box[3] - box[1]
        if height > 0.5 * frame_height:
            return "close"
        elif height > 0.2 * frame_height:
            return "medium"
        else:
            return "far"

    def get_movement(self, track, fps):
        """Determine movement direction and speed."""
        # Access DeepSort state (x, y, ar, h, vx, vy, ...)
        state = track.mean if hasattr(track, 'mean') else [0, 0, 0, 0, 0, 0]
        vx, vy = state[4], state[5]
        speed = (vx**2 + vy**2)**0.5 * fps
        if speed < 10:  # Threshold for stationary
            return "stationary", speed
        direction = "right" if vx > 0 else "left"
        speed_label = "fast" if speed > 200 else "slow"
        return f"{speed_label} {direction}", speed

    def get_action(self, obj_type, movement):
        """Infer basic action from movement."""
        state = "moving" if movement != "stationary" else "stationary"
        return self.action_map.get(obj_type, {}).get(state, "")

    def generate_summary(self, tracks):
        """Generate a scene summary."""
        type_counts = Counter([t['type'] for t in tracks])
        summary = "Currently, there are "
        summary += ", ".join(f"{count} {t}{'s' if count > 1 else ''}" for t, count in type_counts.items())
        if "person" in type_counts:
            closest = min([t for t in tracks if t['type'] == "person"], 
                         key=lambda x: x['distance_order'], default=None)
            if closest:
                summary += f". The closest person is {closest['action']} on the {closest['location']}."
        return summary

    def object_detector(self):
        """Main loop for intelligent object detection and scene analysis."""
        print("ðŸš€ EyeOfOden AI Vision with Speech Activated...")
        fps = self.cap.get(cv2.CAP_PROP_FPS) or 30

        while self.cap.isOpened():
            ret, frame = self.cap.read()
            if not ret:
                print("Failed to capture frame.")
                break

            # Run YOLOv8 for Object Detection
            results = self.model(frame, conf=0.4)
            detections = []
            for result in results:
                for box in result.boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    confidence = box.conf[0].item()
                    class_id = int(box.cls[0].item())
                    obj_type = self.class_labels.get(class_id, "unknown")
                    detections.append([[x1, y1, x2, y2], confidence, obj_type])

            # Track objects using DeepSORT
            tracks = self.tracker.update_tracks(detections, frame=frame)
            current_track_ids = set(track.track_id for track in tracks if track.is_confirmed())
            track_data = []

            # Process each track
            for track in tracks:
                if not track.is_confirmed():
                    continue
                box = track.to_tlbr()
                obj_type = track.det_class if hasattr(track, 'det_class') else "unknown"
                location = self.get_location(box, frame.shape[1])
                distance = self.get_distance(box, frame.shape[0])
                distance_order = {"close": 0, "medium": 1, "far": 2}[distance]
                movement, speed = self.get_movement(track, fps)
                action = self.get_action(obj_type, movement)

                # Store track info
                track_info = {
                    "track_id": track.track_id,
                    "type": obj_type,
                    "location": location,
                    "distance": distance,
                    "distance_order": distance_order,
                    "movement": movement,
                    "speed": speed,
                    "action": action
                }
                track_data.append(track_info)

                # Draw on frame
                x1, y1, x2, y2 = map(int, box)
                label = f"ID: {track.track_id} - {obj_type} ({action})"
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                # Event: Fast-moving object
                if speed > 200:
                    self.speak(f"A fast {obj_type} is moving {movement} on the {location}.")

            # Event: New objects
            new_ids = current_track_ids - self.previous_track_ids
            for track_id in new_ids:
                track = next(t for t in track_data if t["track_id"] == track_id)
                self.speak(f"A new {track['type']} has entered the scene on the {track['location']}.")

            # Periodic Summary (every ~5 seconds)
            self.frame_counter += 1
            if self.frame_counter >= 150:  # 5 seconds at 30 fps
                summary = self.generate_summary(track_data)
                self.speak(summary)
                self.frame_counter = 0

            self.previous_track_ids = current_track_ids

            # Display Frame
            cv2.imshow("EyeOfOden AI Vision", frame)

            # Exit on 'q'
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        # Cleanup
        self.cap.release()
        cv2.destroyAllWindows()
        self.speech_queue.put(None)
        self.speech_thread.join()
        print("EyeOfOden terminated.")

# Activate AI System
if __name__ == "__main__":
    try:
        eye_of_oden = EyeOfOden()
        eye_of_oden.object_detector()
    except Exception as e:
        print(f"Error: {e}")
